{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4mMXs4H62SB"
   },
   "source": [
    "### Welcome!\n",
    "This notebook generates various sound frequency counts from the word frequency data in HKCanCor (Luke & Wong, 2015), which are presented in Li, Alderete, & Badrulhisham (2020). To run the code blocks below, it is recommended that you download the parent folder of this file and run it on [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb) (default, recommended) or on your local installation of [Jupyter Notebooks](https://jupyter.org/).\n",
    "\n",
    "If you're using Colab, go ahead and run the code blocks. If you're using a local installation, please ensure that the packages required are installed in your local system. This notebook can also downloaded as a .py and be ran in your local system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9bJ5zj7Lx0P"
   },
   "source": [
    "If you're running this notebook on your local installation, the blocks from line 2-11 can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdHNZwu--5vu"
   },
   "outputs": [],
   "source": [
    "#package setup\n",
    "try:\n",
    "  !pip install pycantonese\n",
    "  !pip install xlsxwriter\n",
    "except:\n",
    "  pass\n",
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "except:\n",
    "  pass\n",
    "import pycantonese\n",
    "import re\n",
    "from pandas import read_csv\n",
    "from collections import Counter\n",
    "import xlsxwriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pFH6aNNLLfSP"
   },
   "source": [
    "Please adjust the location in line 2 accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfmblB4VFW4i"
   },
   "outputs": [],
   "source": [
    "#workbook setup\n",
    "workbook = xlsxwriter.Workbook(\"hkcancor_phono.xlsx\")\n",
    "wordsize_sheet = workbook.add_worksheet('wordsize')\n",
    "syllshape_sheet = workbook.add_worksheet('syllshape')\n",
    "OvRtoken_sheet = workbook.add_worksheet('tokenOvR')\n",
    "OvRtype_sheet = workbook.add_worksheet('typeOvR')\n",
    "CvTall_sheet = workbook.add_worksheet('CvTall')\n",
    "CvTdisyll_sheet = workbook.add_worksheet('CvTdisyll')\n",
    "phonotactics_sheet = workbook.add_worksheet('phonotactics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_0wMEGPLsnV"
   },
   "source": [
    "Please adjust the location in line 23 accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9RVvtjU6UFC"
   },
   "outputs": [],
   "source": [
    "#loading word frequency .csv\n",
    "def sylldiv(word):\n",
    "    units = re.split('(\\d)', word)\n",
    "    units = units[:-1]\n",
    "    zipped = [''.join(item) for item in zip(units[::2], units[1::2])]\n",
    "    return zipped\n",
    "\n",
    "def parsesyll(syll):\n",
    "    jp = pycantonese.parse_jyutping(syll)[0]\n",
    "    onset = jp[0]\n",
    "    tone = jp[3]\n",
    "    if jp[2] == '':\n",
    "        coda = 'none'\n",
    "    elif jp[2] in 'mnng':\n",
    "        coda = 'nasal'\n",
    "    elif jp[2] in 'aieou':\n",
    "        coda = 'dip'\n",
    "    else:\n",
    "        coda = 'stop'\n",
    "    rime = ''.join(jp[1:3])\n",
    "    return (onset, rime, coda, tone)\n",
    "\n",
    "word_data = read_csv(\"hkcancor_word.csv\", names = ['orthos', 'phonos', 'counts', 'probability'], header = 0)\n",
    "phonos = word_data.phonos.tolist()\n",
    "phonos = [sylldiv(i) for i in phonos]\n",
    "for i in range(0, len(phonos)):\n",
    "    phonos[i] = [parsesyll(j) for j in phonos[i]]\n",
    "tokens = word_data.counts.tolist()\n",
    "tokens = [int(i) for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtVx7kx27vlO"
   },
   "outputs": [],
   "source": [
    "#wordsize\n",
    "wordsize_sheet.write(0, 0, 'syllables')\n",
    "wordsize_sheet.write(0, 1, 'tokens')\n",
    "wordsize_sheet.write(0, 2, 'types')\n",
    "\n",
    "wordsize_list = [len(i) for i in phonos]\n",
    "wordsize_tokens = [0, 0, 0, 0, 0, 0]\n",
    "wordsize_types = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0, len(wordsize_list)):\n",
    "  size_num = wordsize_list[i]\n",
    "  if size_num >= 6:\n",
    "    wordsize_types[5] += 1\n",
    "    wordsize_tokens[5] += int(tokens[i])\n",
    "  else:\n",
    "    wordsize_types[size_num-1] += 1\n",
    "    wordsize_tokens[size_num-1] += int(tokens[i])\n",
    "\n",
    "for i in range(1, 7):\n",
    "  wordsize_sheet.write(i, 0, i)\n",
    "  wordsize_sheet.write(i, 1, wordsize_tokens[i-1])\n",
    "  wordsize_sheet.write(i, 2, wordsize_types[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tR2LUnXUL1KJ"
   },
   "outputs": [],
   "source": [
    "#syllshape\n",
    "def syll_shape(syll):\n",
    "    if syll[0] == '':\n",
    "        onset = ''\n",
    "    else:\n",
    "        onset = 'C'\n",
    "    if syll[2] == 'none':\n",
    "        if syll[1] in 'mng':\n",
    "            return 'C'\n",
    "        else:\n",
    "            return onset+'V'\n",
    "    elif syll[2] == 'dip':\n",
    "        return onset+'VV'\n",
    "    elif syll[2] == 'nasal':\n",
    "        return onset+'VN'\n",
    "    elif syll[2] == 'stop':\n",
    "        return onset+'VS'\n",
    "\n",
    "syllshape_sheet.write(0, 0, 'syllable shape')\n",
    "syllshape_sheet.write(0, 1, 'token count')\n",
    "syllshape_sheet.write(0, 2, 'type count')\n",
    "\n",
    "syllshape_list = ['C', 'V', 'VV', 'VN', 'VS', 'CV', 'CVV', 'CVN', 'CVS']\n",
    "syllshape_tokens = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "syllshape_types = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0, len(phonos)):\n",
    "  for j in phonos[i]:\n",
    "    syllshape_target = syll_shape(j)\n",
    "    syllshape_index = syllshape_list.index(syllshape_target)\n",
    "    syllshape_tokens[syllshape_index] += tokens[i]\n",
    "    syllshape_types[syllshape_index] += 1\n",
    "\n",
    "for i in range(1, 10):\n",
    "  syllshape_sheet.write(i, 0, syllshape_list[i-1])\n",
    "  syllshape_sheet.write(i, 1, syllshape_tokens[i-1])\n",
    "  syllshape_sheet.write(i, 2, syllshape_types[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pIlr4BrsPm1"
   },
   "outputs": [],
   "source": [
    "#setting up types and token list for sub-syllabic analysis\n",
    "subsyll_tokens = []\n",
    "subsyll_types = []\n",
    "disyll_tokens = []\n",
    "disyll_types = []\n",
    "for i in range(0, len(phonos)):\n",
    "  word_check = phonos[i]\n",
    "  if len(word_check) == 2:\n",
    "    disyll_types.append(word_check)\n",
    "    disyll_tokens.extend([word_check]*tokens[i])\n",
    "  for j in word_check:\n",
    "    subsyll_types.append(j)\n",
    "    subsyll_tokens.extend([j]*tokens[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4tIBNBivuVsZ"
   },
   "outputs": [],
   "source": [
    "#onset versus rime\n",
    "onset_list = ['', 'b', 'p', 'd', 't', 'g', 'k', 'gw', 'kw', 'f', 's', 'h', 'z', 'c', 'm', 'n', 'ng', 'w', 'l', 'j']\n",
    "rime_list = ['i', 'e', 'yu', 'oe', 'u', 'o', 'aa', 'ei', 'eoi', 'ui', 'oi', 'ai', 'aai', 'iu', 'eu', 'ou', 'au', 'aau', 'im', 'ip', 'em', 'ep', 'am', 'ap', 'aam', 'aap', 'in', 'it', 'en', 'et', 'yun', 'yut', 'eon', 'eot', 'an', 'at', 'aan', 'aat', 'on', 'ot', 'un', 'ut', 'ing', 'ik', 'eng', 'ek', 'oeng', 'oek', 'ang', 'ak', 'aang', 'aak', 'ong', 'ok', 'ung', 'uk', 'm', 'ng']\n",
    "def OvR(onset, big_list):\n",
    "    input_list = [i[1] for i in big_list if i[0] == onset]\n",
    "    return Counter(input_list)\n",
    "\n",
    "#token onset vs. rime\n",
    "column = 1\n",
    "for i in rime_list:\n",
    "    OvRtoken_sheet.write(0, column, i)\n",
    "    column += 1\n",
    "row = 1\n",
    "for i in onset_list:\n",
    "    OvRtoken_sheet.write(row, 0, i)\n",
    "    column = 1\n",
    "    freq_access = OvR(i, subsyll_tokens)\n",
    "    for j in rime_list:\n",
    "        OvRtoken_sheet.write(row, column, freq_access[j])\n",
    "        column += 1\n",
    "    row += 1\n",
    "\n",
    "#type onset vs. rime\n",
    "column = 1\n",
    "for i in rime_list:\n",
    "    OvRtype_sheet.write(0, column, i)\n",
    "    column += 1\n",
    "row = 1\n",
    "for i in onset_list:\n",
    "    OvRtype_sheet.write(row, 0, i)\n",
    "    column = 1\n",
    "    freq_access = OvR(i, subsyll_types)\n",
    "    for j in rime_list:\n",
    "        OvRtype_sheet.write(row, column, freq_access[str(j)])\n",
    "        column += 1\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGDMh5XQuknl"
   },
   "outputs": [],
   "source": [
    "#coda versus tone\n",
    "coda_list = ['none', 'nasal', 'stop']\n",
    "def CvT(coda, big_list):\n",
    "    if coda == 'none':\n",
    "        input_list = [i[3] for i in big_list if i[2] == 'none' or i[2] == 'dip']\n",
    "    else:\n",
    "        input_list = [i[3] for i in big_list if i[2] == coda]\n",
    "    return Counter(input_list)\n",
    "\n",
    "#all coda versus tone\n",
    "for i in range(1,7):\n",
    "    CvTall_sheet.write(0, i, i)\n",
    "CvTall_sheet.write(1, 0, 'token frequency')\n",
    "CvTall_sheet.write(6, 0, 'type frequency')\n",
    "row = 2\n",
    "for i in coda_list:\n",
    "    CvTall_sheet.write(row, 0, i)\n",
    "    CvTall_sheet.write(row+5, 0, i)\n",
    "    CvTtoken = CvT(i, subsyll_tokens)\n",
    "    CvTtype = CvT(i, subsyll_types)\n",
    "    for j in range(1,7):\n",
    "        CvTall_sheet.write(row, j, CvTtoken[str(j)])\n",
    "        CvTall_sheet.write(row+5, j, CvTtype[str(j)])\n",
    "    row += 1\n",
    "\n",
    "#disyll coda versus tone\n",
    "for i in range(1,7):\n",
    "    CvTdisyll_sheet.write(0, i, i)\n",
    "    CvTdisyll_sheet.write(0, i+7, i)\n",
    "CvTdisyll_sheet.write(1, 0, 'token frequency')\n",
    "CvTdisyll_sheet.write(6, 0, 'type frequency')\n",
    "row = 2\n",
    "for i in coda_list:\n",
    "    CvTall_sheet.write(row, 0, i)\n",
    "    CvTall_sheet.write(row+5, 0, i)\n",
    "    CvT1token = CvT(i, [i[0] for i in disyll_tokens])\n",
    "    CvT2token = CvT(i, [i[1] for i in disyll_tokens])\n",
    "    CvT1type = CvT(i, [i[0] for i in disyll_types])\n",
    "    CvT2type = CvT(i, [i[1] for i in disyll_types])\n",
    "    for j in range(1,7):\n",
    "        CvTdisyll_sheet.write(row, j, CvT1token[str(j)])\n",
    "        CvTdisyll_sheet.write(row, j+7, CvT2token[str(j)])\n",
    "        CvTdisyll_sheet.write(row+5, j, CvT1type[str(j)])\n",
    "        CvTdisyll_sheet.write(row+5, j+7, CvT2type[str(j)])\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elK0HCxgvUXi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#phonotactic violations\n",
    "phonotactics_sheet.write(0, 0, 'category')\n",
    "phonotactics_sheet.write(0, 1, 'tokens')\n",
    "phonotactics_sheet.write(0, 2, 'types')\n",
    "\n",
    "#lab_lab\n",
    "phonotactics_sheet.write(1, 0, '*lab...lab')\n",
    "cat1_search = ['b', 'p', 'm', 'f', 'gw', 'kw']\n",
    "cat1_token_count = 0\n",
    "cat1_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[0] in cat1_search:\n",
    "        for j in cat1_search:\n",
    "            if j in i[1]:\n",
    "                cat1_type_count += 1\n",
    "phonotactics_sheet.write(1, 2, cat1_type_count)\n",
    "\n",
    "if cat1_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[0] in cat1_search:\n",
    "            for j in cat1_search:\n",
    "                if j in i[1]:\n",
    "                    cat1_token_count += 1\n",
    "phonotactics_sheet.write(1, 1, cat1_token_count)\n",
    "\n",
    "#round_lab\n",
    "phonotactics_sheet.write(2, 0, '*round...lab')\n",
    "cat2_search = ['up', 'um', 'op', 'om', 'yp', 'ym', 'yup', 'yum']\n",
    "cat2_token_count = 0\n",
    "cat2_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[1] in cat2_search:\n",
    "        cat2_type_count += 1\n",
    "phonotactics_sheet.write(2, 2, cat2_type_count)\n",
    "\n",
    "if cat2_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[1] in cat2_search:\n",
    "            cat2_token_count += 1\n",
    "phonotactics_sheet.write(2, 1, cat2_token_count)\n",
    "\n",
    "#lab_backround\n",
    "phonotactics_sheet.write(3, 0, '*lab...backround')\n",
    "cat3_search = ['y', 'eo', 'oe']\n",
    "cat3_token_count = 0\n",
    "cat3_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[0] in cat1_search:\n",
    "        if i[1][0] in cat3_search or i[1][:2] in cat3_search:\n",
    "            if i[2] != 'dip':\n",
    "                cat3_type_count += 1\n",
    "phonotactics_sheet.write(3, 2, cat3_type_count)\n",
    "\n",
    "if cat3_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[0] in cat1_search:\n",
    "            if i[1][0] in cat3_search or i[1][:2] in cat3_search:\n",
    "                if i[2] != 'dip':\n",
    "                    cat3_token_count += 1\n",
    "phonotactics_sheet.write(3, 1, cat3_token_count)\n",
    "\n",
    "#cor_backround_cor\n",
    "phonotactics_sheet.write(4, 0, '*cor...backround...cor')\n",
    "cat4_search = ['d', 't', 's', 'n', 'l']\n",
    "cat4_search_vowel = ['o', 'u']\n",
    "cat4_token_count = 0\n",
    "cat4_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[1][1:] in cat4_search:\n",
    "        if i[1][0] in cat4_search_vowel:\n",
    "            if i[0] in cat4_search:\n",
    "                cat4_type_count += 1\n",
    "phonotactics_sheet.write(4, 2, cat4_type_count)\n",
    "\n",
    "if cat4_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[1][1:] in cat4_search:\n",
    "            if i[1][0] in cat4_search_vowel:\n",
    "                if i[0] in cat4_search:\n",
    "                    cat4_token_count += 1\n",
    "phonotactics_sheet.write(4, 1, cat4_token_count)\n",
    "\n",
    "#e_lab/cor\n",
    "phonotactics_sheet.write(5, 0, '*e...lab/cor')\n",
    "cat5_search = ['em', 'en', 'ep', 'et']\n",
    "cat5_token_count = 0\n",
    "cat5_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[1] in cat5_search:\n",
    "        cat5_type_count += 1\n",
    "phonotactics_sheet.write(5, 2, cat5_type_count)\n",
    "\n",
    "if cat5_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[1] in cat5_search:\n",
    "            cat5_token_count += 1\n",
    "phonotactics_sheet.write(5, 1, cat5_token_count)\n",
    "\n",
    "#cor_u\n",
    "phonotactics_sheet.write(6, 0, '*cor...u')\n",
    "cat6_token_count = 0\n",
    "cat6_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[1][0] == 'u' and i[1] not in ['ung', 'uk']:\n",
    "        if i[0] in cat4_search:\n",
    "            cat6_type_count += 1\n",
    "phonotactics_sheet.write(6, 2, cat6_type_count)\n",
    "\n",
    "if cat6_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[1][0] == 'u' and i[1] not in ['ung', 'uk']:\n",
    "            if i[0] in cat4_search:\n",
    "                cat6_token_count += 1\n",
    "phonotactics_sheet.write(6, 1, cat6_token_count)\n",
    "\n",
    "#high_dorsal\n",
    "phonotactics_sheet.write(7, 0, '*high...dorsal')\n",
    "cat7_search = ['yuk', 'yung']\n",
    "cat7_token_count = 0\n",
    "cat7_type_count = 0\n",
    "for i in subsyll_types:\n",
    "    if i[1] in cat7_search:\n",
    "        cat7_type_count += 1\n",
    "phonotactics_sheet.write(7, 2, cat7_type_count)\n",
    "\n",
    "if cat7_type_count != 0:\n",
    "    for i in subsyll_tokens:\n",
    "        if i[1] in cat7_search:\n",
    "            cat7_token_count += 1\n",
    "phonotactics_sheet.write(7, 1, cat7_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaIYyBnw4l_s"
   },
   "outputs": [],
   "source": [
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hkcancor_extract.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
